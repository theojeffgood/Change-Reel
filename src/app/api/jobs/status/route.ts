/**
 * Job Processing Status & Background Processor API
 * 
 * Provides status information and manages automatic background job processing.
 * This API route starts and manages job processing within the Next.js app.
 */

import { NextResponse } from 'next/server'
import { createSupabaseService, getServiceRoleSupabaseService } from '@/lib/supabase/client'

// Background job processing state
let processingInterval: NodeJS.Timeout | null = null
let isProcessingActive = false
const jobStats = {
  processed: 0,
  failed: 0,
  lastProcessedAt: null as Date | null,
  startedAt: null as Date | null
}

// Helper functions from existing /api/jobs/process route
async function processWebhookJobLogic(job: any, supabaseService: any): Promise<{ success: boolean; message?: string; error?: string }> {
  try {
    const data = job.data;
    
    // Only process push events
    if (data.webhook_event !== 'push') {
      return { success: true, message: 'Ignored non-push event' };
    }

    // Extract commits from payload
    const commits = data.payload?.commits || [];
    if (commits.length === 0) {
      return { success: true, message: 'No commits to process' };
    }

    // Get project information
    const { data: projects } = await supabaseService.projects.listProjects();
    if (!projects || projects.length === 0) {
      return { success: false, error: 'No projects found in database' };
    }

    const project = projects[0]; // Use first project for MVP
    
    // Process each commit
    for (const commitData of commits) {
      // Create commit record
      const commitResult = await supabaseService.commits.createCommit({
        project_id: project.id,
        sha: commitData.id,
        message: commitData.message,
        author_name: commitData.author?.name || 'Unknown',
        author_email: commitData.author?.email || 'unknown@example.com',
        timestamp: new Date(commitData.timestamp).toISOString(),
        url: commitData.url,
        diff_content: null, // Will be fetched by diff job
        summary: null, // Will be generated by summary job
      });

      if (commitResult.error) {
        console.error('Failed to create commit:', commitResult.error);
        continue;
      }

      // Create fetch diff job
      const fetchDiffJobResult = await supabaseService.jobs.createJob({
        type: 'fetch_diff',
        data: {
          commit_id: commitResult.data.id,
          commit_sha: commitData.id,
          repository_owner: data.payload?.repository?.owner?.login,
          repository_name: data.payload?.repository?.name,
        },
        priority: 'medium',
      });

      if (!fetchDiffJobResult.error) {
        // Create summary job that depends on diff job
        await supabaseService.jobs.createJob({
          type: 'generate_summary',
          data: {
            commit_id: commitResult.data.id,
          },
          priority: 'medium',
        });
      }
    }

    return { success: true, message: `Processed ${commits.length} commits` };
  } catch (error) {
    return { success: false, error: error instanceof Error ? error.message : 'Unknown error' };
  }
}

// Reset stuck jobs function
async function resetStuckJobs() {
  try {
    const supabase = createSupabaseService()
    
    // Reset jobs that have been "running" for more than 5 minutes back to "pending"
    const fiveMinutesAgo = new Date(Date.now() - 5 * 60 * 1000).toISOString()
    
    const { error } = await supabase.getClient()
      .from('jobs')
      .update({ 
        status: 'pending',
        started_at: null,
        error_message: 'Reset from stuck running state'
      })
      .eq('status', 'running')
      .lt('started_at', fiveMinutesAgo)
    
    if (error) {
      console.error('‚ùå [JobProcessor] Failed to reset stuck jobs:', error)
    } else {
      console.log('üîÑ [JobProcessor] Reset stuck jobs older than 5 minutes')
    }
  } catch (error) {
    console.error('‚ùå [JobProcessor] Error resetting stuck jobs:', error)
  }
}

// Background job processor
async function processJobs() {
  if (isProcessingActive) return // Prevent overlapping executions

  isProcessingActive = true
  try {
    const supabaseService = getServiceRoleSupabaseService()
    
    // Reset stuck jobs on every processing cycle
    await resetStuckJobs()
    
    // Get pending jobs using the service
    const { data: jobs, error } = await supabaseService.jobs.getJobsByFilter({ status: 'pending' })

    if (error) {
      console.error('Failed to fetch pending jobs:', error)
      return
    }

    if (!jobs || jobs.length === 0) {
      return // No jobs to process
    }

    // Limit to 5 jobs at a time
    const jobsToProcess = jobs.slice(0, 5)
    console.log(`üîÑ [JobProcessor] Processing ${jobsToProcess.length} jobs...`)

    // Process each job
    for (const job of jobsToProcess) {
      try {
        await processJob(job, supabaseService)
        jobStats.processed++
        jobStats.lastProcessedAt = new Date()
      } catch (error) {
        console.error(`‚ùå [JobProcessor] Failed to process job ${job.id}:`, error)
        jobStats.failed++
        
        // Mark job as failed
        await supabaseService.jobs.updateJob(job.id, { 
          status: 'failed',
          error_message: error instanceof Error ? error.message : 'Unknown error',
          completed_at: new Date().toISOString()
        })
      }
    }

  } catch (error) {
    console.error('‚ùå [JobProcessor] Error in job processing cycle:', error)
  } finally {
    isProcessingActive = false
  }
}

// Process individual job based on type
async function processJob(job: any, supabaseService: any) {
  console.log(`üîÑ [JobProcessor] Processing ${job.type} job ${job.id}`)
  
  // Mark job as running
  await supabaseService.jobs.updateJob(job.id, { 
    status: 'running', 
    started_at: new Date().toISOString() 
  })

  switch (job.type) {
    case 'fetch_diff':
      await processFetchDiffJob(job, supabaseService)
      break
    case 'generate_summary':
      await processGenerateSummaryJob(job, supabaseService)
      break
    case 'send_email':
      await processSendEmailJob(job, supabaseService)
      break
    case 'webhook_processing':
      await processWebhookJob(job, supabaseService)
      break
    default:
      throw new Error(`Unknown job type: ${job.type}`)
  }

  // Mark job as completed
  await supabaseService.jobs.updateJob(job.id, { 
    status: 'completed',
    completed_at: new Date().toISOString()
  })

  console.log(`‚úÖ [JobProcessor] Completed ${job.type} job ${job.id}`)
}

// Import the actual job processing functions from the existing route
async function processWebhookJobFromExisting(job: any, supabaseService: any): Promise<{ success: boolean; message?: string; data?: any; error?: string }> {
  // This is already implemented above as processWebhookJobLogic
  return processWebhookJobLogic(job, supabaseService)
}

async function processGenerateSummaryJobFromExisting(job: any, supabaseService: any): Promise<{ success: boolean; data?: any; error?: string }> {
  // Use the actual implementation from /api/jobs/process
  try {
    const data = job.data;
    
    // Use OpenAI to generate summary - no fallbacks
    const openai = await import('openai');
    const client = new openai.OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    });

    const prompt = `You are a changelog assistant. Summarize the following commit into a 1-2 sentence plain English description of what changed. Be concise and skip minor edits.

Commit: ${data.commit_message}
Author: ${data.author}
Branch: ${data.branch}

Provide only the summary, no additional text.`;

    const completion = await client.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [{ role: 'user', content: prompt }],
      max_tokens: 100,
      temperature: 0.3
    });

    const summary = completion.choices[0]?.message?.content?.trim();
    
    if (!summary) {
      return {
        success: false,
        error: 'OpenAI returned empty response - no summary generated'
      };
    }

    // Detect change type based on commit message
    const commitMessage = data.commit_message?.toLowerCase() || '';
    let changeType = 'chore';
    if (commitMessage.includes('feat') || commitMessage.includes('add') || commitMessage.includes('new')) {
      changeType = 'feature';
    } else if (commitMessage.includes('fix') || commitMessage.includes('bug')) {
      changeType = 'fix';
    } else if (commitMessage.includes('refactor') || commitMessage.includes('improve')) {
      changeType = 'refactor';
    }

    // Update commit with summary
    const { error: updateError } = await supabaseService.commits.updateCommit(data.commit_id, {
      summary: summary,
      type: changeType
    });

    if (updateError) {
      return {
        success: false,
        error: `Failed to update commit: ${updateError.message}`
      };
    }

    return {
      success: true,
      data: {
        summary: summary,
        change_type: changeType,
        commit_id: data.commit_id
      }
    };
  } catch (error: any) {
    // Categorize OpenAI errors for better handling
    let errorType = 'unknown_error';
    let errorMessage = error.message || 'Unknown error in summary generation';
    
    if (error.status === 429) {
      errorType = 'rate_limit_exceeded';
      errorMessage = `OpenAI rate limit exceeded: ${error.message}`;
    } else if (error.status === 401) {
      errorType = 'api_key_invalid';
      errorMessage = `OpenAI API key invalid: ${error.message}`;
    } else if (error.status === 403) {
      errorType = 'permission_denied';
      errorMessage = `OpenAI permission denied: ${error.message}`;
    } else if (error.status >= 500) {
      errorType = 'openai_server_error';
      errorMessage = `OpenAI server error: ${error.message}`;
    } else if (error.code === 'ENOTFOUND' || error.code === 'ECONNREFUSED') {
      errorType = 'network_error';
      errorMessage = `Network error connecting to OpenAI: ${error.message}`;
    }

    console.error(`‚ùå OpenAI summarization failed (${errorType}):`, errorMessage);
    
    return {
      success: false,
      error: `${errorType}: ${errorMessage}`
    };
  }
}

// Job processor wrapper functions
async function processFetchDiffJob(job: any, supabaseService: any) {
  console.log('üîÑ [JobProcessor] Processing fetch diff job:', job.id)
  // TODO: Implement fetch diff logic using GitHub API
  // For now, just simulate successful completion
  console.log('‚úÖ [JobProcessor] Fetch diff job completed:', job.id)
}

async function processGenerateSummaryJob(job: any, supabaseService: any) {
  console.log('üîÑ [JobProcessor] Processing summary generation job:', job.id)
  
  const result = await processGenerateSummaryJobFromExisting(job, supabaseService)
  if (!result.success) {
    throw new Error(result.error || 'Summary generation failed')
  }
  
  console.log('‚úÖ [JobProcessor] Summary generation job completed:', job.id, `"${result.data?.summary}"`)
}

async function processSendEmailJob(job: any, supabaseService: any) {
  console.log('üîÑ [JobProcessor] Processing send email job:', job.id)
  // TODO: Implement email sending logic
  // For now, just simulate successful completion
  console.log('‚úÖ [JobProcessor] Send email job completed:', job.id)
}

async function processWebhookJob(job: any, supabaseService: any) {
  console.log('üîÑ [JobProcessor] Processing webhook job:', job.id)
  
  const result = await processWebhookJobFromExisting(job, supabaseService)
  if (!result.success) {
    throw new Error(result.error || 'Webhook processing failed')
  }
  
  console.log('‚úÖ [JobProcessor] Webhook job completed:', job.id, result.message)
}

export async function GET() {
  try {
    // Start background processing if not already running
    if (!processingInterval) {
      console.log('üöÄ [JobProcessor] Starting background job processing...')
      
      processingInterval = setInterval(async () => {
        try {
          await processJobs()
        } catch (error) {
          console.error('‚ùå [JobProcessor] Error in processing interval:', error)
        }
      }, 2000) // Process every 2 seconds

      jobStats.startedAt = new Date()
      console.log('‚úÖ [JobProcessor] Background processing started')
    }

            // Get current job statistics
        const supabase = createSupabaseService()
        const { data: pendingJobs } = await supabase.getClient()
          .from('jobs')
          .select('count')
          .eq('status', 'pending')
          .single()

        const { data: runningJobs } = await supabase.getClient()
          .from('jobs')
          .select('count')
          .eq('status', 'running')
          .single()

    return NextResponse.json({
      status: 'running',
      message: 'Background job processing is active',
      running: true,
      queue_stats: {
        pending_jobs: pendingJobs?.count || 0,
        running_jobs: runningJobs?.count || 0,
        processed_total: jobStats.processed,
        failed_total: jobStats.failed,
        last_processed_at: jobStats.lastProcessedAt,
        started_at: jobStats.startedAt
      },
      processor_info: {
        interval_ms: 2000,
        currently_processing: isProcessingActive
      },
      timestamp: new Date().toISOString()
    })

  } catch (error) {
    console.error('‚ùå [JobProcessor] Failed to get status:', error)
    
    return NextResponse.json({
      status: 'error',
      message: 'Failed to get job processing status',
      error: error instanceof Error ? error.message : 'Unknown error',
      timestamp: new Date().toISOString()
    }, { status: 500 })
  }
}

export async function POST() {
  try {
    // Trigger immediate job processing
    if (!processingInterval) {
      return NextResponse.json({
        success: false,
        message: 'Background job processing not started. Call GET first to initialize.',
        timestamp: new Date().toISOString()
      }, { status: 503 })
    }

    // Trigger immediate processing
    await processJobs()

    return NextResponse.json({
      success: true,
      message: 'Immediate job processing triggered',
      note: 'Jobs are processed automatically every 2 seconds. This was a manual trigger.',
      timestamp: new Date().toISOString()
    })

  } catch (error) {
    console.error('Failed to trigger job processing:', error)
    
    return NextResponse.json({
      success: false,
      message: 'Failed to trigger job processing',
      error: error instanceof Error ? error.message : 'Unknown error',
      timestamp: new Date().toISOString()
    }, { status: 500 })
  }
} 